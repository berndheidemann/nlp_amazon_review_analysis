{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Abzug weil der Kunststoff bei der LED leuchte ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>They were working well in the beginning, and a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>Das Gigaset C570HX ist ein Zusatztelefon für e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>An sich bestimmt ein akzeptabler Kopfhörer, le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Nach nichtmal 2 monaten defekt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content rating\n",
       "2196  Abzug weil der Kunststoff bei der LED leuchte ...      5\n",
       "494   They were working well in the beginning, and a...      1\n",
       "1651  Das Gigaset C570HX ist ein Zusatztelefon für e...      5\n",
       "227   An sich bestimmt ein akzeptabler Kopfhörer, le...      1\n",
       "1100                     Nach nichtmal 2 monaten defekt      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Amazon-Deutsch-Dataset.csv\")\n",
    "df = df[[\"content\", \"rating\"]]\n",
    "df.rating= df.rating.str[0]\n",
    "df = df.dropna()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tokenizer-Funktion (einfaches Beispiel)\n",
    "def tokenizer(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Vokabular erstellen\n",
    "def build_vocab(texts, vocab_size):\n",
    "    word_counts = {}\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text)\n",
    "        for token in tokens:\n",
    "            if token in word_counts:\n",
    "                word_counts[token] += 1\n",
    "            else:\n",
    "                word_counts[token] = 1\n",
    "\n",
    "    sorted_vocab = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_vocab = sorted_vocab[:vocab_size-1]\n",
    "    word_to_idx = {word: idx+1 for idx, (word, _) in enumerate(sorted_vocab)}\n",
    "    word_to_idx['<unk>'] = 0\n",
    "    return word_to_idx\n",
    "\n",
    "# Texte in Sequenzen von Wortindizes umwandeln\n",
    "def text_to_indices(text, word_to_idx):\n",
    "    tokens = tokenizer(text)\n",
    "    indices = [word_to_idx[token] if token in word_to_idx else 0 for token in tokens]\n",
    "    return indices\n",
    "\n",
    "# Hyperparameter\n",
    "vocab_size = 10000\n",
    "word_count = 200\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "num_classes = 5\n",
    "batch_size = 32\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# Aufteilung in Trainings- und Testdaten\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Erstellung des Vokabulars\n",
    "texts = train_df['content'].tolist()\n",
    "word_to_idx = build_vocab(texts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mein altes Handy gab den Geist auf - wie das oft so der Fall ist, vor dem verlängerten Wochenende. Also musste ich noch schnell los und mir ein neues besorgen (daher stammt es auch nicht von Amazon). Das klappte - aber dann trat das nächste Problem auf ... ich hatte vorher (im Galaxy S4 Mini) eine MikroSIM und brauchte jetzt eine NanoSIM. Also musste ich eine halbe Stunde vor Landeschluss noch in den T-Shop, um mir eine neue SIM-Karte zu besorgen.\\n\\nAlso - Merkposten Nr. 1 (wenn man von älteren Handys kommt) - neue NanoSIM besorgen!\\n\\nIch bin nicht (mehr) der Ansicht, dass ich immer das allerneuste Handy haben muss. Ein Gerät, das zur \"vorletzten\" Generation gehört (die neuen Galaxy S8er Handys sind ja raus) reicht für mich vollkommen aus (und ist ein Riesenfortschritt zum S4 Mini).\\n\\nWas gefällt mir?\\n- das sehr schöne Display. Gute Größe (für meinen Geschmack) - bietet viel Platz, gute Auflösung, schöne Farben - und ist jedenfalls für mich mit einer Handy bedienbar (habe allerdings auch große Pranken).\\n- 32GB interner Speicher sind schon mal ein Wort und viel besser als die 8GB des vorherigen Geräts (die Erweiterbarkeit über Speicherkarten ist ebenfalls sehr gut)\\n- die Kamera gefällt mir bisher sehr gut, die Bilder sind mit (meinem) Vorgängermodell nicht vergleichbar. Auch ältere Kompaktkameras kommen da nicht hjinterher. Das die Fotos trotz alledem natürlich nicht mit Aufnahmen einer Spiegelreflexkamera vergleichbar sind, sollte sich von selbst verstehen!\\n- die Leistung des Geräts ist für meine Ansprüche vollkommen ausreichend (bzw vermutlich immer noch drastisch überdimensioniert). Ich nutze Handys nicht zum Zocken und auch nicht zum Videoschauen. Bei mir stehen tatsächlich telefonieren, , Messagingdienste wie WhattsApp, Internetnutzung, hin und wieder mal Fotos und vielleicht Musikhören im Zug an erster Stelle - und dafür funktioniert es perfekt. Apps laufen ruckelfrei und ohne Verzögerung.\\n- die Auflasdung funktioiniert über die normalen USB-Buchsen. Es wird kein proprietärer Stecker gebraucht, die gesamte vorhandene Ladeinfrastruktur kann weiter genutzt werden. Was ich demnächst noch ausprobieren werde, ist das induktive Laden, das entsprechende Ladegerät ist bestellt, das kommt sicher noch.\\n- das Always-on-Display. Die Uhrzeit wird durchgehend angezeigt (ich benutze schon seit längerem keine Armbanduhren mehr, daher ist das Handy bei mir auch immer Uhr) und Nachrichten werden durch ein entsprechendes Symbol immer dargestellt.\\n\\nAlso Aoftware war auf meinem Gerät entweder das Android7 bereits installiert oder er hat direkt nach der Inbetriebnahme im Zusammenhang mit der Einrichtung des Geräts auf Android7 upgedatet! Auch insoweit gibt es also nichts zu beanstanden.\\n\\nWas mir nicht so gut gefällt ist die Tatsache, dass es keinen wechselbaren Akku gibt. Das ist ein leidiges Thema, das aber fast alle modernen Handy betrifft ... und vermutlich hier auch u.a. der Wasserdichtigkeit geschuldet ist. Dieselbe allerdings habe ich bisher nicht ausprobiert und wäre auch dankbar, wenn ich das nicht tun müsste.\\nZurück zum Akku - bisher gefällt mir die Akkuleistung recht gut. Ich komme ohne weiteres durch den Tag ohne mir größere Gedanken machen zu müssen, bei etwas weniger Nutzung sind es auch ohne weiteres fast zwei Tage, die der Akku reicht.\\n\\nAlles in allem bin ich sehr zufrieden mit dem Gerät und würde es mir wieder kaufen. Vermissen tue ich nichts und ich wüsste auch aktuell nicht, was ein neueres Smartphone noch besser können sollte.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx[\"Handy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[307, 523, 47, 483, 14, 412, 18, 33, 46, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(texts[0], word_to_idx)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  21,   69,   16,  179,   10,   22,  122, 4016,   67, 1480,   95,  122,\n",
      "        1466,   32,    9, 6146,    0,    4,   27,  163,    0,  212,   21,  170,\n",
      "           8, 1592,   55,  285,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, df, word_count=500, vocab_size=10000):\n",
    "        self.df = df\n",
    "        self.word_count = word_count\n",
    "        self.vocab_size = vocab_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        x= self.df.iloc[idx][\"content\"]\n",
    "        y= self.df.iloc[idx][\"rating\"]\n",
    "        y = int(y) - 1\n",
    "        x = text_to_indices(x, word_to_idx)\n",
    "        # we need this because we need to have a fixed size input\n",
    "        if len(x) > self.word_count:\n",
    "            x=x[:self.word_count]\n",
    "        else:\n",
    "        # pad with zeros, in case the text is shorter than word_count\n",
    "            x.extend([0]*(self.word_count-len(x)))\n",
    "        x = torch.tensor(x)\n",
    "        y= torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n",
    "    \n",
    "amazon_dataset = AmazonDataset(df, word_count=50, vocab_size=vocab_size)\n",
    "x,y=amazon_dataset[0]\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich bin sehr zufrieden mit dem iPhone 11. Der Wechsel vom iPhone 6s war ein riesiger <unk> der sich allerdings <unk> hat. Ich würde es jederzeit wieder kaufen. <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "def indices_to_text(indices, idx_to_word):\n",
    "    tokens = [idx_to_word[idx.item()] for idx in indices]\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "indices_to_text(x, idx_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding-Funktion für Batch\n",
    "def custom_collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)  # this means: separate inputs and labels from the batch\n",
    "    inputs = [torch.tensor(text, dtype=torch.long) for text in inputs]\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=0) \n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50])\n",
      "torch.Size([32])\n",
      "Das Handy ist sehr schön und auch praktisch. Super ist die Kamera. Was mir nicht so gut gefallen hat ist, dass die Anleitung nur auf <unk> ist. <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "tensor(3.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/qjs6b9wn4zx7nh630c4my9lw0000gn/T/ipykernel_16937/2314543085.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(text, dtype=torch.long) for text in inputs]\n"
     ]
    }
   ],
   "source": [
    "# test custom_collate_fn\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(amazon_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "inputs, labels = next(iter(train_loader))\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "print(indices_to_text(inputs[2], idx_to_word))\n",
    "print(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_classes, word_count):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=4,  # Number of attention heads\n",
    "            dim_feedforward=hidden_dim,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(word_count * embedding_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        #print(\"embedded shape: \", embedded.shape)\n",
    "        embedded = embedded.permute(1, 0, 2)  # Shape: (word_count, batch_size, embedding_dim)\n",
    "        #print(\"embedded 2 shape: \", embedded.shape)\n",
    "\n",
    "        transformer_output = self.transformer(embedded)\n",
    "        #print(\"transformer_output shape: \", transformer_output.shape)\n",
    "        #transformer_output = transformer_output.permute(1, 0, 2)  # Back to (batch_size, word_count, embedding_dim)\n",
    "        #print(\"transformer_output 2 shape: \", transformer_output.shape)\n",
    "        transformer_output = transformer_output.contiguous().view(transformer_output.size(0), -1)\n",
    "        #print(\"transformer_output 3 shape: \", transformer_output.shape)\n",
    "        out = self.fc(transformer_output)\n",
    "        #print(\"out shape: \", out.shape)\n",
    "        out = self.relu(out)\n",
    "        #print(\"out 2 shape: \", out.shape)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/qjs6b9wn4zx7nh630c4my9lw0000gn/T/ipykernel_16937/2314543085.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(text, dtype=torch.long) for text in inputs]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (200x4096 and 25600x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#print(\"outputs.shape\", outputs)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#print(\"labels.shape\", labels)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m transformer_output \u001b[39m=\u001b[39m transformer_output\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(transformer_output\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#print(\"transformer_output 3 shape: \", transformer_output.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(transformer_output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#print(\"out shape: \", out.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berndheidemann/Developer/data_science/text/amazon_review_analysis/classifier_with_transformer.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (200x4096 and 25600x1)"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "\n",
    "# Daten laden und Dataloader erstellen\n",
    "train_dataset = AmazonDataset(train_df, word_count, vocab_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modell initialisieren\n",
    "model = TransformerClassifier(vocab_size, embedding_dim, hidden_dim, num_layers, 1, word_count)\n",
    "model=model.to(device)\n",
    "\n",
    "# Optimizer und Loss-Funktion\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Trainingsschleife\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #print(\"outputs.shape\", outputs)\n",
    "        #print(\"labels.shape\", labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n",
    "\n",
    "# Evaluierung auf Testdaten\n",
    "model.eval()\n",
    "test_dataset = AmazonDataset(test_df, word_count, vocab_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 500])\n",
      "predicted tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "text = [\"Das Handy ist sehr gut. Wirklich empfehlenswert!\", \"Das Handy ist sehr schlecht. Nicht empfehlenswert\"]\n",
    "\n",
    "text = [text_to_indices(t, word_to_idx) for t in text]\n",
    "\n",
    "def padd_text_batch(batch):\n",
    "    for t in batch:\n",
    "        if len(t) < word_count:\n",
    "            t.extend([0]*(word_count-len(t)))\n",
    "    return torch.tensor(batch, dtype=torch.long)\n",
    "\n",
    "text = padd_text_batch(text)\n",
    "device = torch.device(\"cpu\")\n",
    "text = text.to(device)\n",
    "# padd with zeros\n",
    "print(text.shape)\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(text)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(\"predicted\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
