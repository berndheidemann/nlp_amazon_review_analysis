{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.901901Z",
     "start_time": "2023-04-26T10:25:47.619629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3409lines [00:00, 4138.77lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9362\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"Amazon-Deutsch-Dataset.csv\")\n",
    "df = df[[\"content\", \"rating\"]]\n",
    "df.rating= df.rating.str[0]\n",
    "df = df.dropna()\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "# create iterator from tokenized df\n",
    "def df_iterator_content(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['content'])\n",
    "\n",
    "vocab = build_vocab_from_iterator(df_iterator_content(df))\n",
    "vocab= torchtext.vocab.Vocab(vocab.freqs, min_freq=2)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.903920Z",
     "start_time": "2023-04-26T10:25:48.902612Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vocab_idx(wordlist):\n",
    "    return [vocab[token] for token in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.909671Z",
     "start_time": "2023-04-26T10:25:48.904342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, df, word_count=500, vocab_size=10000):\n",
    "        self.df = df\n",
    "        self.word_count = word_count\n",
    "        self.vocab_size = vocab_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        x= self.df.iloc[idx][\"content\"]\n",
    "        y= self.df.iloc[idx][\"rating\"]\n",
    "        y = int(y) - 1\n",
    "        x = get_vocab_idx(tokenizer(x))\n",
    "        # we need this because we need to have a fixed size input\n",
    "        if len(x) > self.word_count:\n",
    "            x=x[:self.word_count]\n",
    "        else:\n",
    "        # pad with zeros, in case the text is shorter than word_count\n",
    "            x.extend([0]*(self.word_count-len(x)))\n",
    "        x = torch.tensor(x)\n",
    "        y= torch.tensor(y, dtype=torch.float)\n",
    "        return x, y\n",
    "\n",
    "amazon_dataset = AmazonDataset(df, word_count=100, vocab_size=vocab_size)\n",
    "x,y=amazon_dataset[0]\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.914751Z",
     "start_time": "2023-04-26T10:25:48.910011Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, word_count=50, dropout=0.3, num_lstm_layers=2):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.num_lstm_layers=num_lstm_layers\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_lstm_layers, dropout=dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        # The linear layer that maps from hidden state space to output space\n",
    "        self.fc1=nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 300),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.BatchNorm1d(300)\n",
    "        )\n",
    "        self.fc2=torch.nn.Sequential(\n",
    "            torch.nn.Linear(300, 1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.smallfc=torch.nn.Linear(word_count*hidden_dim, 1)\n",
    "        self.smallfc.bias=torch.nn.Parameter(torch.tensor([2.5]))\n",
    "        \n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.word_embeddings(xb)\n",
    "        out, _ = self.lstm(out)\n",
    "        #print(\"out 0 shape\", out.shape) # batch_size, word_count, hidden_dim\n",
    "        # reshape to batch_size, word_count*hidden_dim\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        #print(\"hidden shape\", hidden.shape)\n",
    "        #print(\"internal shape\", internal.shape) # num_layers, batch_size, hidden_dim\n",
    "        # reshape to batch_size, num_layers*hidden_dim\n",
    "        #out = internal.reshape(internal.shape[1], -1)\n",
    "        #out = out.reshape(out.shape[0], -1)\n",
    "        #out=hidden[-1]\n",
    "        #print(\"shape of out before fc\", out.shape)\n",
    "        \n",
    "        #print(\"shape of out after\", out.shape)\n",
    "        #out=hidden.view(-1, self.hidden_dim)\n",
    "        out=self.smallfc(out)\n",
    "        #print(\"out shape\", out.shape)\n",
    "        #out = out.view(xb.shape[0], -1)\n",
    "        #print(\"out 2 shape\", out.shape)\n",
    "        #out = out[:,-1]\n",
    "        #print(\"out 3 shape\", out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.951807Z",
     "start_time": "2023-04-26T10:25:48.916467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb tensor([1., 0., 4., 3., 2.])\n",
      "xb torch.Size([5, 200])\n",
      "y_hat torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 32\n",
    "hidden_dim = 32\n",
    "word_count = 200\n",
    "\n",
    "model = MyLSTM(embed_dim, hidden_dim, vocab_size, word_count=word_count, num_lstm_layers=5)\n",
    "dataset = AmazonDataset(df, word_count=word_count, vocab_size=vocab_size)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# check if model works\n",
    "xb, yb = next(iter(loader))\n",
    "\n",
    "print(\"yb\", yb)\n",
    "print(\"xb\", xb.shape)\n",
    "\n",
    "y_hat=model(xb)\n",
    "print(\"y_hat\", y_hat.shape)\n",
    "# 2x5x32 ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:48.961649Z",
     "start_time": "2023-04-26T10:25:48.959340Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#device=torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.L1Loss() # L1 Loss is used for regression, it computes the mean absolute error between the input and the target\n",
    "loss_func=torch.nn.BCELoss() # Binary Cross Entropy Loss is used for binary classification\n",
    "#loss_func = torch.nn.MSELoss() \n",
    "\n",
    "def evaluate(model, hidden, dataloader):\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (xb, yb) in enumerate(dataloader):\n",
    "            xb=xb.to(device)\n",
    "            yb=yb.to(device)\n",
    "            yb=yb[:,None]\n",
    "            predicted_label = model(xb, hidden)\n",
    "            loss=loss_func(predicted_label, yb)\n",
    "            sum_loss += loss.item()\n",
    "    return sum_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T10:25:26.764221Z",
     "start_time": "2023-04-26T10:24:50.988377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/autograd/__init__.py:204: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682406555958/work/aten/src/ATen/mps/MPSFallback.mm:12.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  5.82s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  3.23s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  3.18s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  3.16s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  3.18s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  3.16s | train MAE    1.499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  3.27s | train MAE    1.499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 40\u001b[0m     loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_sum \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#valid_loss = evaluate(model, valid_dataloader)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 30 # epoch\n",
    "LR = 0.01  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "embed_dim = 64\n",
    "hidden_dim = 128\n",
    "word_count = 200\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10.0, gamma=0.7)   # every 10 epochs, LR is multiplied by 0.7\n",
    "model= MyLSTM(embed_dim, hidden_dim, vocab_size, word_count=200, dropout=0.2, num_lstm_layers=3).to(device)\n",
    "total_accu = None\n",
    "train_accus=[]\n",
    "valid_accus=[]\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    sum_loss, total_count = 0, 0\n",
    "    loss_sum = 0\n",
    "    for idx, (xb, yb) in enumerate(train_dataloader):\n",
    "        if len(xb) < BATCH_SIZE:\n",
    "            break\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        # this adds a dimension to yb, so that it is compatible with the loss function\n",
    "        optimizer.zero_grad()\n",
    "        y_hat= model(xb)\n",
    "        #print(\"y_hat.shape\", y_hat.shape)\n",
    "        #print(\"yb.shape\", yb.shape)\n",
    "        loss = loss_func(y_hat.view(-1), yb)\n",
    "        loss.backward()      \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    train_loss = loss_sum / len(train_dataloader)\n",
    "    #valid_loss = evaluate(model, valid_dataloader)\n",
    "    train_accus.append(train_loss)\n",
    "    #valid_accus.append(valid_loss)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train MAE {:8.3f}'.format(\n",
    "                                epoch,\n",
    "                                time.time() - epoch_start_time,\n",
    "                                train_loss))\n",
    "                                #valid_loss))\n",
    "                                #scheduler.get_last_lr()[0]))\n",
    "    \n",
    "\n",
    "    #scheduler.step() # learning rate scheduler after each epoch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accus, label='train_accu')\n",
    "plt.plot(valid_accus, label='valid_accu')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.4136],\n",
       "         [2.4466],\n",
       "         [2.4842],\n",
       "         [2.4320],\n",
       "         [2.5507],\n",
       "         [2.4718],\n",
       "         [2.4039],\n",
       "         [2.3655],\n",
       "         [2.4971],\n",
       "         [2.4743],\n",
       "         [2.4780],\n",
       "         [2.4264],\n",
       "         [2.4361],\n",
       "         [2.5185],\n",
       "         [2.4659],\n",
       "         [2.4254],\n",
       "         [2.4923],\n",
       "         [2.3527],\n",
       "         [2.3910],\n",
       "         [2.4144],\n",
       "         [2.5046],\n",
       "         [2.4339],\n",
       "         [2.4247],\n",
       "         [2.3941],\n",
       "         [2.5411],\n",
       "         [2.4734],\n",
       "         [2.4525],\n",
       "         [2.3663],\n",
       "         [2.5700],\n",
       "         [2.3883],\n",
       "         [2.3988],\n",
       "         [2.4640],\n",
       "         [2.3993],\n",
       "         [2.4536],\n",
       "         [2.4956],\n",
       "         [2.4840],\n",
       "         [2.4029],\n",
       "         [2.3800],\n",
       "         [2.4596],\n",
       "         [2.4407],\n",
       "         [2.3874],\n",
       "         [2.3902],\n",
       "         [2.4490],\n",
       "         [2.4045],\n",
       "         [2.4668],\n",
       "         [2.3232],\n",
       "         [2.4432],\n",
       "         [2.2997],\n",
       "         [2.3441],\n",
       "         [2.3835],\n",
       "         [2.4566],\n",
       "         [2.4722],\n",
       "         [2.4316],\n",
       "         [2.4235],\n",
       "         [2.4021],\n",
       "         [2.3998],\n",
       "         [2.4228],\n",
       "         [2.3761],\n",
       "         [2.4912],\n",
       "         [2.4623],\n",
       "         [2.5106],\n",
       "         [2.4029],\n",
       "         [2.3584],\n",
       "         [2.3078]], device='mps:0', grad_fn=<LinearBackward0>),\n",
       " (tensor([[[ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926],\n",
       "           [ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926],\n",
       "           [ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926],\n",
       "           ...,\n",
       "           [ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926],\n",
       "           [ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926],\n",
       "           [ 0.0327, -0.2784,  0.1731,  ..., -0.2914,  0.4951, -0.1926]],\n",
       "  \n",
       "          [[-0.0517,  0.1531,  0.1413,  ...,  0.0165, -0.0962,  0.2647],\n",
       "           [-0.1191,  0.1929,  0.0405,  ...,  0.0524, -0.1335,  0.2447],\n",
       "           [-0.1930,  0.1806,  0.1185,  ..., -0.0220, -0.1896,  0.3092],\n",
       "           ...,\n",
       "           [ 0.0127,  0.1083,  0.0849,  ...,  0.0572, -0.1906,  0.2614],\n",
       "           [-0.1753,  0.2053,  0.1135,  ..., -0.0519, -0.1403,  0.3180],\n",
       "           [-0.1631,  0.1875,  0.1389,  ...,  0.0431, -0.2441,  0.1808]],\n",
       "  \n",
       "          [[ 0.0312,  0.0123,  0.1362,  ..., -0.0670, -0.0667,  0.0606],\n",
       "           [-0.1200, -0.0050,  0.0238,  ..., -0.0411, -0.1404,  0.0643],\n",
       "           [ 0.1287, -0.0621,  0.0944,  ..., -0.0103, -0.0390, -0.0710],\n",
       "           ...,\n",
       "           [-0.0797, -0.1967,  0.0784,  ...,  0.0238, -0.1637, -0.0275],\n",
       "           [ 0.0296,  0.0221,  0.0185,  ..., -0.0863, -0.1513, -0.0094],\n",
       "           [ 0.0527, -0.0939,  0.0354,  ..., -0.0223, -0.1356,  0.0458]]],\n",
       "         device='mps:0', grad_fn=<LstmMpsBackward0>),\n",
       "  tensor([[[ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680],\n",
       "           [ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680],\n",
       "           [ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680],\n",
       "           ...,\n",
       "           [ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680],\n",
       "           [ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680],\n",
       "           [ 0.0715, -0.6705,  0.3559,  ..., -0.6871,  1.3740, -0.4680]],\n",
       "  \n",
       "          [[-0.0869,  0.4892,  0.2502,  ...,  0.0392, -0.2200,  0.7709],\n",
       "           [-0.1986,  0.5942,  0.0822,  ...,  0.1462, -0.2837,  0.6451],\n",
       "           [-0.3715,  0.4149,  0.2329,  ..., -0.0605, -0.4097,  0.7823],\n",
       "           ...,\n",
       "           [ 0.0201,  0.2848,  0.1578,  ...,  0.1265, -0.3683,  0.8636],\n",
       "           [-0.3589,  0.5061,  0.2254,  ..., -0.1587, -0.3196,  0.8735],\n",
       "           [-0.2598,  0.4935,  0.2456,  ...,  0.0925, -0.5667,  0.4869]],\n",
       "  \n",
       "          [[ 0.0511,  0.0325,  0.3254,  ..., -0.1489, -0.1744,  0.1294],\n",
       "           [-0.1947, -0.0116,  0.0446,  ..., -0.0757, -0.2961,  0.1463],\n",
       "           [ 0.2531, -0.1223,  0.1686,  ..., -0.0240, -0.0659, -0.2195],\n",
       "           ...,\n",
       "           [-0.1420, -0.3975,  0.1809,  ...,  0.0576, -0.3158, -0.0771],\n",
       "           [ 0.0494,  0.0529,  0.0368,  ..., -0.1874, -0.2631, -0.0314],\n",
       "           [ 0.1252, -0.2381,  0.0738,  ..., -0.0494, -0.2891,  0.1064]]],\n",
       "         device='mps:0', grad_fn=<LstmMpsBackward0>)))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb=next(iter(valid_dataloader))\n",
    "xb=xb.to(device)\n",
    "model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T09:23:04.703421Z",
     "start_time": "2023-04-26T09:23:04.055407Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 1 required positional argument: 'dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# how much valid accuracy do we get in a new untrained model?\u001b[39;00m\n\u001b[1;32m      2\u001b[0m new_model \u001b[38;5;241m=\u001b[39m MyLSTM(embed_dim, hidden_dim, vocab_size, word_count\u001b[38;5;241m=\u001b[39mword_count)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: 'dataloader'"
     ]
    }
   ],
   "source": [
    "# how much valid accuracy do we get in a new untrained model?\n",
    "new_model = MyLSTM(embed_dim, hidden_dim, vocab_size, word_count=word_count).to(device)\n",
    "evaluate(new_model, valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
